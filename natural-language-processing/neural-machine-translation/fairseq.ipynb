{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "fairseq",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U96IO9APGH_l"
   },
   "source": [
    "# Setup Libraries and Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install bert-score\n",
    "\n",
    "!mkdir data\n",
    "!wget https://ahmadian.me/nmt/train.en -O data/train.en\n",
    "!wget https://ahmadian.me/nmt/train.fa -O data/train.fa\n",
    "!wget https://ahmadian.me/nmt/train-min.en -O data/train-min.en\n",
    "!wget https://ahmadian.me/nmt/train-min.fa -O data/train-min.fa\n",
    "!wget https://ahmadian.me/nmt/valid.en -O data/valid.en\n",
    "!wget https://ahmadian.me/nmt/valid.fa -O data/valid.fa\n",
    "!wget https://ahmadian.me/nmt/test.en -O data/test.en\n",
    "!wget https://ahmadian.me/nmt/test.fa -O data/test.fa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "trainEnFile = 'data/train.en'\n",
    "trainFaFile = 'data/train.fa'\n",
    "trainMinEnFile = 'data/train-min.en'\n",
    "trainMinFaFile = 'data/train-min.fa'\n",
    "validEnFile = 'data/valid.en'\n",
    "validFaFile = 'data/valid.fa'\n",
    "testEnFile = 'data/test.en'\n",
    "testFaFile = 'data/test.fa'"
   ],
   "metadata": {
    "id": "jE_BJGtZY9B-"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainEnFileProc = 'data/train.proc.en'\n",
    "trainFaFileProc = 'data/train.proc.fa'\n",
    "trainMinEnFileProc = 'data/train-min.proc.en'\n",
    "trainMinFaFileProc = 'data/train-min.proc.fa'\n",
    "validEnFileProc = 'data/valid.proc.en'\n",
    "validFaFileProc = 'data/valid.proc.fa'\n",
    "testEnFileProc = 'data/test.proc.en'\n",
    "testFaFileProc = 'data/test.proc.fa'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(trainEnFile, 'r') as file:\n",
    "    data = file.read().lower()\n",
    "\n",
    "text_file = open(trainEnFileProc, \"w\")\n",
    "text_file.write(data)\n",
    "text_file.close()\n",
    "\n",
    "with open(trainMinEnFile, 'r') as file:\n",
    "    data = file.read().lower()\n",
    "\n",
    "text_file = open(trainMinEnFileProc, \"w\")\n",
    "text_file.write(data)\n",
    "text_file.close()\n",
    "\n",
    "with open(validEnFile, 'r') as file:\n",
    "    data = file.read().lower()\n",
    "\n",
    "text_file = open(validEnFileProc, \"w\")\n",
    "text_file.write(data)\n",
    "text_file.close()\n",
    "\n",
    "with open(testEnFile, 'r') as file:\n",
    "    data = file.read().lower()\n",
    "\n",
    "text_file = open(testEnFileProc, \"w\")\n",
    "text_file.write(data)\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "\n",
    "with open(trainFaFile, 'r') as file:\n",
    "    data = file.read().replace('\\u200c', ' ')\n",
    "\n",
    "text_file = open(trainFaFileProc, \"w\")\n",
    "text_file.write(data)\n",
    "text_file.close()\n",
    "\n",
    "with open(trainMinFaFile, 'r') as file:\n",
    "    data = file.read().replace('\\u200c', ' ')\n",
    "\n",
    "text_file = open(trainMinFaFileProc, \"w\")\n",
    "text_file.write(data)\n",
    "text_file.close()\n",
    "\n",
    "with open(validFaFile, 'r') as file:\n",
    "    data = file.read().replace('\\u200c', ' ')\n",
    "\n",
    "text_file = open(validFaFileProc, \"w\")\n",
    "text_file.write(data)\n",
    "text_file.close()\n",
    "\n",
    "with open(testFaFile, 'r') as file:\n",
    "    data = file.read().replace('\\u200c', ' ')\n",
    "\n",
    "text_file = open(testFaFileProc, \"w\")\n",
    "text_file.write(data)\n",
    "text_file.close()"
   ],
   "metadata": {
    "id": "zEY9pwYwY9ua"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TBPKwPbhPDrR"
   },
   "source": [
    "%%capture\n",
    "# W and B -- For Logging\n",
    "! pip install wandb\n",
    "\n",
    "# Sacremoses -- For Tokenizing\n",
    "! pip install sacremoses\n",
    "\n",
    "! git clone https://github.com/pytorch/fairseq\n",
    "%cd fairseq\n",
    "! pip install --editable ./\n",
    "%cd ..\n",
    "\n",
    "! echo $PYTHONPATH\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
    "\n",
    "! echo $PYTHONPATH"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b9YRiMzHdafl"
   },
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtPG1WlBGQ7w"
   },
   "source": [
    "## Pre-process and Binarize to build Vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OycGg77va6xt"
   },
   "source": [
    "! fairseq-preprocess --source-lang en --target-lang fa \\\n",
    "  --trainpref data/train.proc \\\n",
    "  --validpref data/valid.proc \\\n",
    "  --testpref  data/test.proc \\\n",
    "  --destdir data/tokenized \\\n",
    "  --thresholdsrc 2 \\\n",
    "  --thresholdtgt 2 \\\n",
    "  --bpe byte_bpe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCHShbvQGVfv"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5RGvS-Yxb8C8"
   },
   "source": [
    "! fairseq-train data/tokenized \\\n",
    "  --arch transformer \\\n",
    "  --dropout 0.1 \\\n",
    "  --attention-dropout 0.1 \\\n",
    "  --activation-dropout 0.1 \\\n",
    "  --encoder-embed-dim 256 \\\n",
    "  --encoder-ffn-embed-dim 512 \\\n",
    "  --encoder-layers 3 \\\n",
    "  --encoder-attention-heads 8 \\\n",
    "  --encoder-learned-pos \\\n",
    "  --decoder-embed-dim 256 \\\n",
    "  --decoder-ffn-embed-dim 512 \\\n",
    "  --decoder-layers 3 \\\n",
    "  --decoder-attention-heads 8 \\\n",
    "  --decoder-learned-pos \\\n",
    "  --max-epoch 20 \\\n",
    "  --optimizer adam \\\n",
    "  --lr 5e-4 \\\n",
    "  --batch-size 128 \\\n",
    "  --scoring bleu \\\n",
    "  --seed 1 \\\n",
    "  --wandb-project \"fairseq\" \\\n",
    "  --bpe byte_bpe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R52sr1X2GYuI"
   },
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint1.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint2.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint3.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint4.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint5.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint6.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint7.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint8.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint9.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint10.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint11.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint12.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint13.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint14.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint15.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint16.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint17.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint18.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint19.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint20.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bleu \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\""
   ],
   "metadata": {
    "id": "jgqpMJu6YMJV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint1.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint2.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint3.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint4.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint5.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint6.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint7.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint8.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint9.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint10.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint11.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint12.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint13.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint14.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint15.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint16.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint17.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint18.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint19.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint20.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring bert_score \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\""
   ],
   "metadata": {
    "id": "YGWMoohndPjK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint1.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint2.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint3.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint4.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint5.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint6.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint7.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint8.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint9.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint10.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint11.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint12.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint13.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint14.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint15.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint16.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint17.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint18.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint19.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\"\n",
    "\n",
    "! fairseq-generate data/tokenized \\\n",
    "    --path checkpoints/checkpoint20.pt \\\n",
    "    --batch-size 128 \\\n",
    "    --beam 10 \\\n",
    "    --seed 1 \\\n",
    "    --scoring wer \\\n",
    "    --quiet \\\n",
    "    --wandb-project \"fairseq\""
   ],
   "metadata": {
    "id": "W1S-NJ6Ed_9p"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
