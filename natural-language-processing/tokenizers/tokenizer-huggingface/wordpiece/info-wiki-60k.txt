[00:00:29] Pre-processing files (543 Mo)            █████████████████████████████████████████████████████████████████████████████████████                100%
[00:00:02] Tokenize words                           █████████████████████████████████████████████████████████████████████████████████████ 610142   /   610142
[00:00:04] Count pairs                              █████████████████████████████████████████████████████████████████████████████████████ 610142   /   610142
[00:00:07] Compute merges                           █████████████████████████████████████████████████████████████████████████████████████ 21268    /    21268

['Hell', '##o', ',', 'y', "'", 'all', '!', 'How', 'are', 'you', '[UNK]', '?']
[15338, 5018, 16, 93, 11, 9007, 5, 11835, 8891, 9491, 0, 35]
