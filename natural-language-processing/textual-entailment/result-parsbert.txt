Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
100%
30/30 [20:09<00:00, 40.88s/it]

Epoch 1
Training loss: 1.1207556203007698
Class: c: 0.0
Class: n: 0.0
Class: e: 1.0
Validation loss: 1.115234094507554
Validation F1 Score (Weighted): 0.12950191570881225

Epoch 2
Training loss: 1.093186301489671
Class: c: 0.0
Class: n: 0.0
Class: e: 1.0
Validation loss: 1.1396954480339498
Validation F1 Score (Weighted): 0.12950191570881225

Epoch 3
Training loss: 1.093505931397279
Class: c: 0.0
Class: n: 0.0
Class: e: 1.0
Validation loss: 1.1630746897529154
Validation F1 Score (Weighted): 0.12950191570881225

Epoch 4
Training loss: 1.080041065812111
Class: c: 0.0
Class: n: 0.0
Class: e: 1.0
Validation loss: 1.153373493867762
Validation F1 Score (Weighted): 0.12950191570881225

Epoch 5
Training loss: 1.0749531276524067
Class: c: 0.045871559633027525
Class: n: 0.012048192771084338
Class: e: 1.0
Validation loss: 1.1411107287687414
Validation F1 Score (Weighted): 0.17486473559919888

Epoch 6
Training loss: 1.0197999651233356
Class: c: 0.3302752293577982
Class: n: 0.6506024096385542
Class: e: 0.38461538461538464
Validation loss: 1.0687282576280481
Validation F1 Score (Weighted): 0.43798211671956294

Epoch 7
Training loss: 0.9335942752659321
Class: c: 0.3761467889908257
Class: n: 0.40963855421686746
Class: e: 0.6410256410256411
Validation loss: 1.0955981927759506
Validation F1 Score (Weighted): 0.46494803550908326

Epoch 8
Training loss: 0.8853018805384636
Class: c: 0.24770642201834864
Class: n: 0.4578313253012048
Class: e: 0.6923076923076923
Validation loss: 1.0954133517601912
Validation F1 Score (Weighted): 0.4292733550907521

Epoch 9
Training loss: 0.7659603208303452
Class: c: 0.3211009174311927
Class: n: 0.6506024096385542
Class: e: 0.5
Validation loss: 1.1354253327145296
Validation F1 Score (Weighted): 0.4685409270211827

Epoch 10
Training loss: 0.6477993962665399
Class: c: 0.5504587155963303
Class: n: 0.5542168674698795
Class: e: 0.47435897435897434
Validation loss: 1.12410849683425
Validation F1 Score (Weighted): 0.5311169047103684

Epoch 11
Training loss: 0.5339157413691282
Class: c: 0.4036697247706422
Class: n: 0.40963855421686746
Class: e: 0.6666666666666666
Validation loss: 1.2648486775510452
Validation F1 Score (Weighted): 0.48172698394578134

Epoch 12
Training loss: 0.4180056826832394
Class: c: 0.3944954128440367
Class: n: 0.42168674698795183
Class: e: 0.6410256410256411
Validation loss: 1.3966887382900013
Validation F1 Score (Weighted): 0.47412458018490855

Epoch 13
Training loss: 0.3079740417500337
Class: c: 0.5504587155963303
Class: n: 0.5060240963855421
Class: e: 0.5128205128205128
Validation loss: 1.3540054559707642
Validation F1 Score (Weighted): 0.5286967501136562

Epoch 14
Training loss: 0.28420341076950234
Class: c: 0.7247706422018348
Class: n: 0.25301204819277107
Class: e: 0.44871794871794873
Validation loss: 1.577723874765284
Validation F1 Score (Weighted): 0.47927330361689163

Epoch 15
Training loss: 0.23325215823327503
Class: c: 0.5412844036697247
Class: n: 0.37349397590361444
Class: e: 0.5641025641025641
Validation loss: 1.62150178937351
Validation F1 Score (Weighted): 0.49592980080486115

Epoch 16
Training loss: 0.15906208536277214
Class: c: 0.6697247706422018
Class: n: 0.42168674698795183
Class: e: 0.3974358974358974
Validation loss: 1.6680960444843067
Validation F1 Score (Weighted): 0.5091794005030285

Epoch 17
Training loss: 0.13965547713451087
Class: c: 0.5596330275229358
Class: n: 0.42168674698795183
Class: e: 0.5512820512820513
Validation loss: 1.8776753860361435
Validation F1 Score (Weighted): 0.5189965654877936

Epoch 18
Training loss: 0.08200846239924431
Class: c: 0.5779816513761468
Class: n: 0.6144578313253012
Class: e: 0.38461538461538464
Validation loss: 1.8880814348950106
Validation F1 Score (Weighted): 0.530204758473236

Epoch 19
Training loss: 0.07854734107968397
Class: c: 0.5321100917431193
Class: n: 0.5542168674698795
Class: e: 0.4230769230769231
Validation loss: 2.1518530144410977
Validation F1 Score (Weighted): 0.5103544290344865

Epoch 20
Training loss: 0.06394506137197216
Class: c: 0.5688073394495413
Class: n: 0.5542168674698795
Class: e: 0.4358974358974359
Validation loss: 2.165410217116861
Validation F1 Score (Weighted): 0.526171958865484

Epoch 21
Training loss: 0.05139308665335799
Class: c: 0.6055045871559633
Class: n: 0.4939759036144578
Class: e: 0.48717948717948717
Validation loss: 2.328188454403597
Validation F1 Score (Weighted): 0.5389049764049764

Epoch 22
Training loss: 0.04731079048360698
Class: c: 0.5321100917431193
Class: n: 0.43373493975903615
Class: e: 0.5769230769230769
Validation loss: 2.5436101520762726
Validation F1 Score (Weighted): 0.5190505886736712

Epoch 23
Training loss: 0.023065382318842847
Class: c: 0.5412844036697247
Class: n: 0.46987951807228917
Class: e: 0.5512820512820513
Validation loss: 2.636025484870462
Validation F1 Score (Weighted): 0.5257612941848395

Epoch 24
Training loss: 0.022349129067151807
Class: c: 0.5504587155963303
Class: n: 0.42168674698795183
Class: e: 0.5384615384615384
Validation loss: 2.6748157739639282
Validation F1 Score (Weighted): 0.508855132152679

Epoch 25
Training loss: 0.02284783070596556
Class: c: 0.5871559633027523
Class: n: 0.43373493975903615
Class: e: 0.5
Validation loss: 2.6841020093244663
Validation F1 Score (Weighted): 0.5161384624210091

Epoch 26
Training loss: 0.023110793743398972
Class: c: 0.5963302752293578
Class: n: 0.3855421686746988
Class: e: 0.5256410256410257
Validation loss: 2.807756956885843
Validation F1 Score (Weighted): 0.5100870300794688

Epoch 27
Training loss: 0.01467744973100101
Class: c: 0.5412844036697247
Class: n: 0.5662650602409639
Class: e: 0.47435897435897434
Validation loss: 2.7223484796636246
Validation F1 Score (Weighted): 0.530515947674166

Epoch 28
Training loss: 0.01692711829188435
Class: c: 0.5412844036697247
Class: n: 0.4578313253012048
Class: e: 0.5897435897435898
Validation loss: 2.892724079244277
Validation F1 Score (Weighted): 0.533391018018529

Epoch 29
Training loss: 0.018924701090630453
Class: c: 0.5596330275229358
Class: n: 0.46987951807228917
Class: e: 0.5512820512820513
Validation loss: 2.809644565862768
Validation F1 Score (Weighted): 0.5327228300619139

Epoch 30
Training loss: 0.013487768277021436
Class: c: 0.5504587155963303
Class: n: 0.4578313253012048
Class: e: 0.5897435897435898
Validation loss: 2.872191478224362
Validation F1 Score (Weighted): 0.5369065091287314

Best validation loss in epoch: 6

Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Class: c: 0.21568627450980393
Class: n: 0.6832669322709163
Class: e: 0.4540983606557377
Test F1 Score (Weighted): 0.4238110659361631